import torch.nn as nn


class AverageAttention(nn.Module):
    def __init__(self):
        """
           Module: Average Attention
           Name: "Accelerating Neural Transformer via an Average Attention Network"
           Link: https://arxiv.org/abs/1805.00631

        """
        super(AverageAttention, self).__init__()
        raise NotImplementedError

    def forward(self, inputs):
        raise NotImplementedError
